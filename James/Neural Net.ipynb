{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import shutil\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist0 = os.listdir('./campics/greensmall/')\n",
    "mylist1 = os.listdir('./campics/yellowsmall/')\n",
    "mylist2 = os.listdir('./campics/yellowfat/')\n",
    "mylist3 = os.listdir('./campics/orangesmall/')\n",
    "mylist4 = os.listdir('./campics/orangedic/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=[]\n",
    "y=[]\n",
    "\n",
    "for i in range(len(mylist0)):\n",
    "    image.append(cv2.imread('./campics/greensmall/'+ str(mylist0[i])))\n",
    "    y.append(0)\n",
    "for i in range(len(mylist1)):\n",
    "    image.append(cv2.imread('./campics/yellowsmall/'+ str(mylist1[i])))\n",
    "    y.append(1)\n",
    "for i in range(len(mylist2)):\n",
    "    image.append(cv2.imread('./campics/yellowfat/'+ str(mylist2[i])))\n",
    "    y.append(2)\n",
    "for i in range(len(mylist3)):\n",
    "    image.append(cv2.imread('./campics/orangesmall/'+ str(mylist3[i])))\n",
    "    y.append(3)\n",
    "for i in range(len(mylist4)):\n",
    "    image.append(cv2.imread('./campics/orangedic/'+ str(mylist4[i])))\n",
    "    y.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 60 #480/4 #120\n",
    "width = 80 #640/4 #160\n",
    "\n",
    "dim = (width, height)\n",
    "\n",
    "resized_image=[]\n",
    " \n",
    "# resize image\n",
    "\n",
    "for i in range(len(image)):\n",
    "    resized_image.append(cv2.resize(image[i], dim, interpolation = cv2.INTER_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "image_train= np.array(resized_image).astype('float32') /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1297, 60, 80, 3)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_train, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to use with Keras API\n",
    "from  keras.utils import np_utils\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],60, 80, 3).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 60, 80, 3).astype('float32')\n",
    "y_train = np_utils.to_categorical(y_train,5)\n",
    "y_test = np_utils.to_categorical(y_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "input_shape = (60, 80, 3)\n",
    "batch_size = 250\n",
    "num_classes = 5\n",
    "epochs = 8 #Can change but for now =1 just to test\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.categorical_crossentropy,\n",
    "              optimizer=optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1037 samples, validate on 260 samples\n",
      "Epoch 1/10\n",
      "1037/1037 [==============================] - 12s 12ms/step - loss: 0.6651 - acc: 0.6750 - val_loss: 0.7084 - val_acc: 0.5808\n",
      "Epoch 2/10\n",
      "1037/1037 [==============================] - 11s 11ms/step - loss: 0.6423 - acc: 0.6905 - val_loss: 0.6402 - val_acc: 0.6192\n",
      "Epoch 3/10\n",
      "1037/1037 [==============================] - 12s 11ms/step - loss: 0.5971 - acc: 0.7377 - val_loss: 0.5306 - val_acc: 0.7231\n",
      "Epoch 4/10\n",
      "1037/1037 [==============================] - 12s 12ms/step - loss: 0.6113 - acc: 0.7001 - val_loss: 0.5379 - val_acc: 0.7192\n",
      "Epoch 5/10\n",
      "1037/1037 [==============================] - 14s 14ms/step - loss: 0.5699 - acc: 0.7194 - val_loss: 0.6319 - val_acc: 0.5962\n",
      "Epoch 6/10\n",
      "1037/1037 [==============================] - 13s 12ms/step - loss: 0.5547 - acc: 0.7252 - val_loss: 0.4909 - val_acc: 0.7577\n",
      "Epoch 7/10\n",
      "1037/1037 [==============================] - 12s 12ms/step - loss: 0.5434 - acc: 0.7483 - val_loss: 0.5572 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "1037/1037 [==============================] - 12s 12ms/step - loss: 0.5211 - acc: 0.7425 - val_loss: 0.5146 - val_acc: 0.6769\n",
      "Epoch 9/10\n",
      "1037/1037 [==============================] - 12s 12ms/step - loss: 0.4922 - acc: 0.7435 - val_loss: 0.4524 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "1037/1037 [==============================] - 12s 12ms/step - loss: 0.4830 - acc: 0.7686 - val_loss: 0.5733 - val_acc: 0.6692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb3865f4358>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5733397263746995\n",
      "Test accuracy: 0.6692307692307692\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_obs1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_obs1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.loadtxt('bigfile.dat', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_result = []\n",
    "\n",
    "#data = np.loadtxt('bigfile3.dat', dtype=float)\n",
    "#for i in range (2000):\n",
    "    # reading in image\n",
    "    ii=i\n",
    "    k = ii*2500    \n",
    "    data1 = data[(0+k):(2500+k)]    \n",
    "    data1 = np.reshape(data1, (50,50))\n",
    "    datat = np.rot90(data1)\n",
    "    datat = np.array(datat)\n",
    "    \n",
    "    # Reshape and append\n",
    "    sample=[]\n",
    "    sample.append(datat)\n",
    "    sample = np.array(sample)\n",
    "    sample = sample.reshape(sample.shape[0],50, 50 , 1).astype('float32')\n",
    "    \n",
    "    # Prediction\n",
    "    prediction = model.predict_classes(sample)\n",
    "    p = prediction[0]\n",
    "    p_result.append(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
