{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to do - review colours for red, green and yellow\n",
    "improve x-y coordinate stuff\n",
    "work on get force stuff!\n",
    "\n",
    "For some reason my shit is not working - might have to try simple approach of just going over it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries!\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil\n",
    "import time\n",
    "import logging\n",
    "import urx\n",
    "from urx.robotiq_two_finger_gripper import Robotiq_Two_Finger_Gripper\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# from urx.urrtmon import URRTMonitor\n",
    "\n",
    "#image: http://192.168.1.6:4242/current.jpg?type=color\n",
    "\n",
    "cam_init_pos = [-0.00043183961977177887, -1.651595417653219, -1.226389233266012, -1.276344124470846, -4.72298783460726, 0.001785649568773806]\n",
    "bucket_pos = [1.6486937999725342, -2.4073990027057093, -1.8858941237079065, -0.36886865297426397, -4.742553655301229, 0.0471811443567276]\n",
    "hardcode_object_loc = [-0.024045769368306935, -1.8617809454547327, -1.511141602193014, -1.4511950651751917, -4.672266546879904, 0.047373268753290176]\n",
    "bucket_pick = [-0.04573041597475225, -1.8159015814410608, -1.2815788427936, -1.4384973684894007, -4.67054266134371, 0.04719312861561775]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teach_bins(rob):\n",
    "    '''\n",
    "    Allows user to move robot to placement of bins\n",
    "    Also need to allow user to take photo of object!??\n",
    "    '''\n",
    "    colours = []\n",
    "    bins = []\n",
    "    n_bins = int(raw_input(\"Please enter the number of bins you have: \"))\n",
    "    for i in range(n_bins):\n",
    "        rob.set_freedrive(1, timeout=60)\n",
    "        colours.append(raw_input(\"Press color of bin when complete: \"))\n",
    "        bins.append(rob.getj())\n",
    "        \n",
    "    print(\"Completed all bins!\")\n",
    "    return [colours, bins]\n",
    "\n",
    "def get_image():\n",
    "    '''\n",
    "    Recieve latest image and save it in a folder\n",
    "    '''\n",
    "    \n",
    "    image_url = \"http://192.168.1.6:4242/current.jpg?type=color\"\n",
    "    \n",
    "    resp = requests.get(image_url, stream=True)\n",
    "    # Open a local file with wb ( write binary ) permission.\n",
    "    img_string = 'images/latest_image.jpg'\n",
    "    local_file = open(img_string, 'wb')\n",
    "    # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "    resp.raw.decode_content = True\n",
    "    # Copy the response stream raw data to local image file.\n",
    "    shutil.copyfileobj(resp.raw, local_file)\n",
    "    # Remove the image url response object.\n",
    "    del resp\n",
    "    \n",
    "    im = cv2.imread('images/latest_image.jpg')\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"image recieved\")\n",
    "\n",
    "def detect_photos(colour):\n",
    "    '''\n",
    "    Read in latest image and detect blobs of the given colour\n",
    "    return the distance to the top left blob in form [X_from_center, Y_from_center] else returns None\n",
    "    '''\n",
    "    f = \"images/latest_image.jpg\"\n",
    "\n",
    "    # two ranges because red stretchs over the Hue colour range\n",
    "    \n",
    "    ##RED\n",
    "    lower_red_1 = (0,100,50)\n",
    "    upper_red_1 = (5,255,255)\n",
    "\n",
    "    lower_red_2 = (170,100,50)\n",
    "    upper_red_2 = (180,255,255)\n",
    "    \n",
    "    ##GREEN\n",
    "    lower_green = (45, 100, 50)\n",
    "    upper_green = (65, 255, 255)\n",
    "    \n",
    "    ##YELLOW\n",
    "    lower_yellow = (30, 100, 50)\n",
    "    upper_yellow = (45, 255, 255)\n",
    "\n",
    "\n",
    "\n",
    "    # reading in image to RGB and HSV\n",
    "    img_RGB = cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB)\n",
    "    img_HSV = cv2.cvtColor(img_RGB, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    if colour == 'red':\n",
    "\n",
    "        # Create two masks\n",
    "        mask1 = cv2.inRange(img_HSV, lower_red_1, upper_red_1)\n",
    "        mask2 = cv2.inRange(img_HSV, lower_red_2, upper_red_2)\n",
    "\n",
    "        # XOR masks\n",
    "        mask = cv2.bitwise_xor(mask1, mask2)\n",
    "    elif colour == 'green':\n",
    "        mask = cv2.inRange(img_HSV, lower_green, upper_green)\n",
    "\n",
    "    elif colour == 'yellow':\n",
    "        mask = cv2.inRange(img_HSV, lower_yellow, upper_yellow)\n",
    "\n",
    "\n",
    "    # bitwise and with image\n",
    "    result = cv2.bitwise_and(img_HSV, img_HSV, mask=mask)\n",
    "\n",
    "\n",
    "    # put median blur over the top\n",
    "    median = cv2.medianBlur(mask,23)\n",
    "\n",
    "    print(\"pixel count: \" + str(cv2.countNonZero(median)))\n",
    "\n",
    "    if cv2.countNonZero(median) < 2000:\n",
    "        print(\"no more objects in scene of colour: \" + colour)\n",
    "        return None\n",
    "\n",
    "    # find connected components\n",
    "    ret, labels = cv2.connectedComponents(median)\n",
    "\n",
    "    # Map component labels to hue val\n",
    "    label_hue = np.uint8(179*labels/np.max(labels))\n",
    "    blank_ch = 255*np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "\n",
    "    # cvt to BGR for display\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # set bg label to black\n",
    "    labeled_img[label_hue==0] = 0\n",
    "\n",
    "    #########################################################\n",
    "    ## Finding Centers!\n",
    "    ret,thresh = cv2.threshold(median,127,255,0)\n",
    "\n",
    "    # find contours in the binary image\n",
    "    ___, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    distance_min = 100000\n",
    "    for c in contours:\n",
    "        # calculate moments for each contour\n",
    "        M = cv2.moments(c)\n",
    "\n",
    "        # calculate x,y coordinate of center\n",
    "        if M[\"m00\"] != 0:\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(labeled_img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "\n",
    "            distance_new = np.sqrt(cX**2 + cY**2)\n",
    "            if distance_new < distance_min:\n",
    "                distance_min = distance_new\n",
    "                X_top_left = cX\n",
    "                Y_top_left = cY\n",
    "\n",
    "            print(\"centerpoints at: x: \" + str(cX) + \" y: \" + str(cY))\n",
    "\n",
    "    print(\"top left points are: x: \" + str(X_top_left) + \" y: \" + str(Y_top_left))\n",
    "\n",
    "#     X_from_center = X_top_left - (640/2)\n",
    "#     Y_from_center = Y_top_left - (480/2)\n",
    "\n",
    "#     print(\"distance from center: x: \" + str(X_from_center) + \" y: \" + str(Y_from_center))\n",
    "\n",
    "    # print out figures\n",
    "    figure = plt.figure(figsize=(20,20))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    # mask\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.subplot(1, 4, 2)\n",
    "    # median blue\n",
    "    plt.imshow(median)\n",
    "    #original image\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(img_RGB)\n",
    "    # final \n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(labeled_img)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "#     return [X_from_center, Y_from_center]\n",
    "    return [X_top_left, Y_top_left]\n",
    "\n",
    "def test_robot(a = 0.2, v = 0.3):\n",
    "    '''\n",
    "    Test to see if robot is behaving normally\n",
    "    '''\n",
    "    # connecting to robot and initialising gripper\n",
    "    while(1):\n",
    "        try:\n",
    "            rob = urx.Robot(\"192.168.1.6\")\n",
    "        except:\n",
    "            print(\"didnt connect, try again\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    robotiqgrip = Robotiq_Two_Finger_Gripper(rob)\n",
    "\n",
    "    robotiqgrip.open_gripper()\n",
    "\n",
    "    # move to initial position\n",
    "    rob.movej(cam_init_pos, acc = a, vel = v)\n",
    "\n",
    "\n",
    "    pose = rob.getj()\n",
    "    print(\"robot tcp is at pose: \", pose)\n",
    "\n",
    "    rob.close()\n",
    "\n",
    "def go_to_start(rob):\n",
    "    rob.movej(cam_init_pos, acc = a, vel = v)\n",
    "    print(\"moved to init position\")\n",
    "    \n",
    "\n",
    "def rob_connect():\n",
    "    while(1):\n",
    "        try:\n",
    "            rob = urx.Robot(\"192.168.1.6\")\n",
    "        except:\n",
    "            print(\"didnt connect, try again\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            robotiqgrip = Robotiq_Two_Finger_Gripper(rob)\n",
    "            return rob\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def convert_to_mm(x, y):\n",
    "    '''\n",
    "    return mm from center!\n",
    "    '''\n",
    "    x = x - (640/2)\n",
    "    y = y - (480/2)\n",
    "    \n",
    "    \n",
    "    x = ((44.0/640.0) / 100) * x\n",
    "    y = ((40.0/(480.0)) / 100) * y + 0.015\n",
    "    y = y / 1.2\n",
    "    \n",
    "    \n",
    "    return [x, y]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# initalise\n",
    "rob = rob_connect()\n",
    "robotiqgrip = Robotiq_Two_Finger_Gripper(rob)\n",
    "a = 0.7; v = 2\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "robotiqgrip.open_gripper()\n",
    "go_to_start(rob)\n",
    "[colours, bins] = teach_bins(rob)\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    if i == len(colours):\n",
    "        print(\"finishing program\")\n",
    "        break\n",
    "        \n",
    "    go_to_start(rob)\n",
    "    time.sleep(1)\n",
    "    get_image()\n",
    "    distance = detect_photos(colours[i])\n",
    "    \n",
    "    if distance == None:\n",
    "        i+=1\n",
    "        continue\n",
    "        \n",
    "\n",
    "    [x_dist, y_dist] = convert_to_mm(distance[0], distance[1])\n",
    "    print(x_dist)\n",
    "    print(y_dist)\n",
    "\n",
    "    rob.translate((y_dist-0.095, x_dist, -0.33), acc=a, vel=v)\n",
    "\n",
    "    robotiqgrip.close_gripper()\n",
    "    rob.movejs([cam_init_pos, bins[i]], acc = a, vel = v, radius=0.2)\n",
    "    robotiqgrip.open_gripper()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################3\n",
    "\n",
    "# pose = rob.getj()\n",
    "# print(pose)\n",
    "# # pose[3] = pose[3] - 0.57\n",
    "# # rob.movel(pose, acc = a, vel = v)\n",
    "\n",
    "# rob.movel_tool([0, 0, 0, -0.43, 0, 0],acc=a, vel=v)\n",
    "\n",
    "rob.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/ur5/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/ur5/lib/python2.7/site-packages/urx-0.11.0-py2.7.egg/urx/ursecmon.py\", line 289, in run\n",
      "    data = self._get_data()\n",
      "  File \"/opt/miniconda3/envs/ur5/lib/python2.7/site-packages/urx-0.11.0-py2.7.egg/urx/ursecmon.py\", line 336, in _get_data\n",
      "    tmp = self._s_secondary.recv(1024)\n",
      "timeout: timed out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# initalise\n",
    "rob = rob_connect()\n",
    "robotiqgrip = Robotiq_Two_Finger_Gripper(rob)\n",
    "a = 0.7; v = 2\n",
    "\n",
    "search_height = [-0.0016549269305627945, -1.1934168974505823, -1.608189884816305, -1.3525961081134241, -4.72298783460726, 0.0012347496813163161]\n",
    "position = [-0.006367985402242482, -0.7724340597735804, -1.7444632689105433, -1.6369636694537562, -4.721239630375997, -0.0024092833148401382]\n",
    "\n",
    "#######################################\n",
    "\n",
    "robotiqgrip.open_gripper()\n",
    "\n",
    "rob.movej(cam_init_pos, acc = a, vel = v)\n",
    "time.sleep(1)\n",
    "#rob.movej(search_height, acc = a, vel = v)\n",
    "current_pos = rob.getj()\n",
    "rob.translate([-0.4,0,0], acc=a, vel=v)\n",
    "\n",
    "rob.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "didnt connect, try again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/ur5/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/ur5/lib/python2.7/site-packages/urx-0.11.0-py2.7.egg/urx/ursecmon.py\", line 289, in run\n",
      "    data = self._get_data()\n",
      "  File \"/opt/miniconda3/envs/ur5/lib/python2.7/site-packages/urx-0.11.0-py2.7.egg/urx/ursecmon.py\", line 336, in _get_data\n",
      "    tmp = self._s_secondary.recv(1024)\n",
      "timeout: timed out\n",
      "\n"
     ]
    },
    {
     "ename": "RobotException",
     "evalue": "Goal not reached but no program has been running for 5 seconds. dist is 1.06914617332, threshold is 0.85531070429, target is [-0.006367985402242482, -0.7724340597735804, -1.7444632689105433, -1.6369636694537562, -4.721239630375997, -0.0024092833148401382], current pose is [0.09841095512571593, -0.05074344937266884, 0.6861433653668018, -1.599420476912998, 0.851961691525063, -0.33678841984673075]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRobotException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-112eea6036e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovej\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/ur5/lib/python2.7/site-packages/urx-0.11.0-py2.7.egg/urx/urrobot.pyc\u001b[0m in \u001b[0;36mmovej\u001b[0;34m(self, joints, acc, vel, wait, relative, threshold)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ur5/lib/python2.7/site-packages/urx-0.11.0-py2.7.egg/urx/urrobot.pyc\u001b[0m in \u001b[0;36m_wait_for_move\u001b[0;34m(self, target, threshold, timeout, joints)\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRobotException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goal not reached but no program has been running for {} seconds. dist is {}, threshold is {}, target is {}, current pose is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mURRobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRobotException\u001b[0m: Goal not reached but no program has been running for 5 seconds. dist is 1.06914617332, threshold is 0.85531070429, target is [-0.006367985402242482, -0.7724340597735804, -1.7444632689105433, -1.6369636694537562, -4.721239630375997, -0.0024092833148401382], current pose is [0.09841095512571593, -0.05074344937266884, 0.6861433653668018, -1.599420476912998, 0.851961691525063, -0.33678841984673075]"
     ]
    }
   ],
   "source": [
    "# initalise\n",
    "rob = rob_connect()\n",
    "robotiqgrip = Robotiq_Two_Finger_Gripper(rob)\n",
    "a = 0.7; v = 2\n",
    "\n",
    "rob.movej(position + [0,0,0,0,0,0.2], acc = a, vel = v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CALLIBRATING IMAGE\n",
    "\n",
    "# # initalise\n",
    "\n",
    "# %matplotlib tk\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# fig = plt.figure(figsize=(20,30))\n",
    "# get_image()\n",
    "# img=mpimg.imread('images/latest_image.jpg')\n",
    "\n",
    "# all_val = []\n",
    "\n",
    "# def onclick(event):\n",
    "#     ix, iy = event.xdata, event.ydata\n",
    "#     print(ix, iy)\n",
    "#     [x, y] = convert_to_mm(ix, iy)\n",
    "#     print(x, y)\n",
    "    \n",
    "    \n",
    "#     rob = rob_connect()\n",
    "#     robotiqgrip = Robotiq_Two_Finger_Gripper(rob)\n",
    "#     a = 0.7; v = 2\n",
    "#     robotiqgrip.close_gripper()\n",
    "    \n",
    "#     rob.translate((y, x, 0), acc=a, vel=v)\n",
    "#     rob.translate((-0.1, 0, 0), acc=a, vel=v)\n",
    "#     rob.translate((0, 0, -0.33), acc=a, vel=v)\n",
    "#     time.sleep(1)\n",
    "#     rob.movej(cam_init_pos, acc = a, vel = v)\n",
    "#     rob.close()\n",
    "    \n",
    "\n",
    "    \n",
    "# cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "# imgplot = plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rob = rob_connect()\n",
    "# robotiqgrip = Robotiq_Two_Finger_Gripper(rob)\n",
    "# a = 0.7; v = 2\n",
    "\n",
    "# rob_force = URRTMonitor(rob)\n",
    "\n",
    "# print(rob_force.get_all_data())\n",
    "\n",
    "# rob.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # just get red\n",
    "# ####################\n",
    "# %matplotlib inline\n",
    "\n",
    "# # initalise\n",
    "# rob = rob_connect()\n",
    "# robotiqgrip = Robotiq_Two_Finger_Gripper(rob)\n",
    "# a = 0.7; v = 2\n",
    "\n",
    "# robotiqgrip.open_gripper()\n",
    "# go_to_start(rob)\n",
    "\n",
    "# while True:\n",
    "#     go_to_start(rob)\n",
    "#     time.sleep(2)\n",
    "#     get_image()\n",
    "#     distance = detect_photos('green')\n",
    "    \n",
    "#     if distance == None:\n",
    "#         print(\"finishing program\")\n",
    "#         break\n",
    "        \n",
    "#     print(distance)\n",
    "#     [x_dist, y_dist] = convert_to_mm(distance[0], distance[1])\n",
    "#     print(x_dist)\n",
    "#     print(y_dist)\n",
    "\n",
    "#     rob.translate(((y_dist)-0.095, x_dist, -0.33), acc=a, vel=v)\n",
    "\n",
    "#     robotiqgrip.close_gripper()\n",
    "#     rob.movejs([cam_init_pos, bucket_pos], acc = a, vel = v, radius=0.2)\n",
    "#     robotiqgrip.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## get robot back into init pos\n",
    "test_robot(a = 1, v = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_to_start(rob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
